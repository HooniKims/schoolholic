// ===== ë¡œì»¬ LLM (Ollama) ì„¤ì • =====
const OLLAMA_API_URL = "https://api.alluser.site";
const OLLAMA_API_KEY = process.env.NEXT_PUBLIC_OLLAMA_API_KEY || "";

export const AVAILABLE_MODELS = [
    { id: "qwen3:8b", name: "Qwen 3 8B (ì¶”ì²œ)", description: "ê· í˜• ì¡íŒ ì„±ëŠ¥" },
    { id: "glm-4.7-flash", name: "GLM-4.7-Flash", description: "ì´ˆê²½ëŸ‰ ë¹ ë¥¸ ì‘ë‹µ" },
    { id: "gemma3:12b-it-q8_0", name: "Gemma 3 12B Q8", description: "ìµœê³  í’ˆì§ˆ (13GB)" },
    { id: "gemma3:12b-it-q4_K_M", name: "Gemma 3 12B Q4", description: "ê³ í’ˆì§ˆ (8GB)" },
    { id: "gemma3:4b-it-q4_K_M", name: "Gemma 3 4B", description: "ê²½ëŸ‰ (3.3GB)" },
    { id: "qwen3:4b", name: "Qwen 3 4B", description: "ê²½ëŸ‰ ë¹ ë¥¸ ì‘ë‹µ" },
    { id: "llama3.1:8b", name: "Llama 3.1 8B", description: "ë²”ìš© ëª¨ë¸" },
];

export const DEFAULT_MODEL = AVAILABLE_MODELS[0].id;

// ===== í•µì‹¬ API í˜¸ì¶œ í•¨ìˆ˜ =====

/**
 * Ollama API 1íšŒ í˜¸ì¶œ (OpenAI í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸)
 * ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ api.alluser.siteë¡œ í˜¸ì¶œ
 */
async function callOllamaAPI(
    systemMessage: string,
    userPrompt: string,
    model?: string,
    options: { temperature?: number; stream?: boolean } = {}
): Promise<string> {
    const { temperature = 0.7, stream = false } = options;

    const res = await fetch(`${OLLAMA_API_URL}/v1/chat/completions`, {
        method: "POST",
        headers: {
            "Content-Type": "application/json",
            "X-API-Key": OLLAMA_API_KEY,
        },
        body: JSON.stringify({
            model: model || DEFAULT_MODEL,
            messages: [
                { role: "system", content: systemMessage },
                { role: "user", content: userPrompt },
            ],
            temperature,
            stream,
        }),
    });

    if (!res.ok) {
        let errorMessage = `ì„œë²„ ì˜¤ë¥˜ (${res.status})`;
        try {
            const errorData = await res.json();
            errorMessage = errorData.error || errorMessage;
        } catch {
            // ë¬´ì‹œ
        }
        throw new Error(errorMessage);
    }

    const data = await res.json();
    return data.choices?.[0]?.message?.content || "";
}

// ===== í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ ìœ í‹¸ =====

/**
 * AI ì¶œë ¥ì—ì„œ ë©”íƒ€ ì •ë³´(ê¸€ììˆ˜, ë¶„ì„ ë‚´ìš© ë“±) ì œê±°
 */
function cleanMetaInfo(text: string): string {
    if (!text) return text;

    // ê´„í˜¸ ì•ˆì˜ ë©”íƒ€ ì •ë³´: (ì•½ 500ì), (ê¸€ììˆ˜: 330) ë“±
    let cleaned = text.replace(/\s*\([^)]*\d+ì[^)]*\)/g, '');
    cleaned = cleaned.replace(/\s*\([^)]*ê¸€ì[^)]*\)/g, '');
    cleaned = cleaned.replace(/\s*\([^)]*ìì„¸í•œ[^)]*\)/g, '');
    cleaned = cleaned.replace(/\s*\([^)]*ë‚´ìš©\s*í¬í•¨[^)]*\)/g, '');

    // ëë¶€ë¶„: "--- 330ì" ë˜ëŠ” "[330ì]"
    cleaned = cleaned.replace(/\s*[-â”€]+\s*\d+ì\s*$/g, '');
    cleaned = cleaned.replace(/\s*\[\d+ì\]\s*$/g, '');
    cleaned = cleaned.replace(/\s*\d+ì\s*$/g, '');

    // ë¶„ì„/ê²€ì¦ ê´€ë ¨ ë¬¸êµ¬ ì œê±°
    cleaned = cleaned.replace(/\s*\[ë¶„ì„[^\]]*\]/g, '');
    cleaned = cleaned.replace(/\s*\[ê²€ì¦[^\]]*\]/g, '');

    return cleaned.trim();
}

/**
 * í…ìŠ¤íŠ¸ê°€ ì™„ì „í•œ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ëë‚˜ëŠ”ì§€ í™•ì¸
 */
function endsWithCompleteSentence(text: string): boolean {
    if (!text || !text.trim()) return false;
    const trimmed = text.trim();
    return /[í•¨ìŒì„ë¨ë´„ì˜´ì¤Œì¶¤ì›€ëŠ ë¦„ë‹¤ìš”ê¹Œë‹ˆ][.!?]\s*$/.test(trimmed);
}

// ===== ê³ ìˆ˜ì¤€ API í•¨ìˆ˜ =====

/**
 * Sandwich ê¸°ë²• ì ìš© â€” ì¶”ê°€ ì§€ì¹¨ì„ ì‹œìŠ¤í…œ/ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì•ë’¤ì— ì‚½ì…
 */
async function generateWithInstructions({
    systemMessage,
    prompt,
    additionalInstructions,
    model,
}: {
    systemMessage: string;
    prompt: string;
    additionalInstructions?: string;
    model?: string;
}): Promise<string> {
    // ì¶”ê°€ ì§€ì¹¨ â†’ ì‹œìŠ¤í…œ ë©”ì‹œì§€ì— ì¶”ê°€
    let finalSystemMessage = systemMessage;
    if (additionalInstructions) {
        finalSystemMessage += `\n\nì‚¬ìš©ì ì¶”ê°€ ê·œì¹™ (ìµœìš°ì„  ì¤€ìˆ˜):\n${additionalInstructions}`;
    }

    // ì¶”ê°€ ì§€ì¹¨ â†’ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì•ë’¤ì— ê°ì‹¸ê¸° (Sandwich ê¸°ë²•)
    let finalPrompt = prompt;
    if (additionalInstructions && additionalInstructions.trim()) {
        const prefix = `[ìµœìš°ì„  ê·œì¹™] ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ì§€ì¼œì„œ ì‘ì„±í•˜ë¼: ${additionalInstructions}\n\n`;
        const suffix = `\n\n[ë‹¤ì‹œ í•œë²ˆ ê°•ì¡°] ìœ„ ë³¸ë¬¸ ì‘ì„± ì‹œ ë°˜ë“œì‹œ ì ìš©í•  ê·œì¹™: ${additionalInstructions}`;
        finalPrompt = prefix + prompt + suffix;
    }

    return callOllamaAPI(finalSystemMessage, finalPrompt, model);
}

/**
 * ìë™ ì¬ì‹œë„ í¬í•¨ API í˜¸ì¶œ
 * ë¬¸ì¥ì´ ë¶ˆì™„ì „í•˜ê²Œ ëë‚˜ë©´ ìµœëŒ€ 2íšŒ ì¬ì‹œë„
 */
async function generateWithRetry(params: {
    systemMessage: string;
    prompt: string;
    additionalInstructions?: string;
    model?: string;
}): Promise<string> {
    let content = await generateWithInstructions(params);

    if (!content.trim()) {
        throw new Error("AI ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.");
    }

    const MAX_RETRIES = 2;
    for (let retry = 0; retry < MAX_RETRIES; retry++) {
        if (endsWithCompleteSentence(content)) break;

        console.log(`[ì¬ì‹œë„ ${retry + 1}/${MAX_RETRIES}] ë¬¸ì¥ ë¶ˆì™„ì „: "...${content.slice(-30)}"`);

        const retryPrompt = `ë‹¤ìŒ í…ìŠ¤íŠ¸ëŠ” ë¬¸ì¥ì´ ì¤‘ê°„ì— ëŠê²¼ìŠµë‹ˆë‹¤. ê°™ì€ ë‚´ìš©ì„ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ëë‚˜ë„ë¡ ë‹¤ì‹œ ì‘ì„±í•˜ì„¸ìš”. ë°˜ë“œì‹œ ì¢…ê²°ì–´ë¯¸ì™€ ë§ˆì¹¨í‘œë¡œ ëë‚´ì„¸ìš”. ì˜¤ì§ ë³¸ë¬¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n\në¶ˆì™„ì „í•œ í…ìŠ¤íŠ¸:\n${content}`;

        const retryContent = await callOllamaAPI(params.systemMessage, retryPrompt, params.model);

        if (retryContent.trim() && endsWithCompleteSentence(retryContent)) {
            content = retryContent;
            console.log(`[ì¬ì‹œë„ ì„±ê³µ] ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ìˆ˜ì •ë¨`);
            break;
        } else if (retryContent.trim()) {
            content = retryContent;
        }
    }

    return content;
}

// ===== ì•Œë¦¼ì¥ ìš”ì•½ ë©”ì¸ í•¨ìˆ˜ =====

/**
 * êµì‚¬ì˜ ì•Œë¦¼ì¥ ë©”ëª¨ë¥¼ AIë¡œ ì •ë¦¬í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
 * 
 * @param text - êµì‚¬ê°€ ì‘ì„±í•œ ë©”ëª¨ ì›ë¬¸
 * @param dateObj - ì•Œë¦¼ì¥ ë‚ ì§œ
 * @param model - ì‚¬ìš©í•  ëª¨ë¸ (ì„ íƒ, ê¸°ë³¸ê°’: DEFAULT_MODEL)
 * @returns ì •ë¦¬ëœ ì•Œë¦¼ì¥ í…ìŠ¤íŠ¸
 */
export async function summarizeNote(
    text: string,
    dateObj: Date,
    model?: string
): Promise<string> {
    if (!text) return "";

    if (!OLLAMA_API_KEY) {
        throw new Error(
            "Ollama API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env.local íŒŒì¼ì—ì„œ NEXT_PUBLIC_OLLAMA_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        );
    }

    // ë‚ ì§œ í¬ë§·íŒ…
    const d = new Date(dateObj);
    const days = ['ì¼', 'ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† '];
    const formattedDate = `${d.getFullYear()}ë…„ ${d.getMonth() + 1}ì›” ${d.getDate()}ì¼(${days[d.getDay()]})`;

    const systemMessage = `ë‹¹ì‹ ì€ ì´ˆë“±í•™êµ ë‹´ì„ì„ ìƒë‹˜ì˜ ì•Œë¦¼ì¥ ì‘ì„±ì„ ë•ëŠ” ì „ë¬¸ ë¹„ì„œì…ë‹ˆë‹¤.
êµì‚¬ì˜ ë©”ëª¨ë¥¼ í•™ë¶€ëª¨ì™€ í•™ìƒ ëª¨ë‘ê°€ ì½ê¸° í¸í•œ ì•Œë¦¼ì¥ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.

<ë¬¸ì²´ ê·œì¹™>
- ì¹œì ˆí•˜ê³  í¸ì•ˆí•œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤ (~í•´ìš”, ~í•©ë‹ˆë‹¤, ~ë“œë ¤ìš”, ~ì£¼ì„¸ìš”)
- ë”±ë”±í•œ ê³µë¬¸ì²´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
- í•™ë¶€ëª¨ì™€ í•™ìƒ ëª¨ë‘ì—ê²Œ ë§í•˜ë“¯ ë”°ëœ»í•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤
</ë¬¸ì²´ ê·œì¹™>

<ì„œì‹ ê·œì¹™>
- ë§ˆí¬ë‹¤ìš´ ì„œì‹ì„ ì ê·¹ í™œìš©í•©ë‹ˆë‹¤
- ì¤‘ìš”í•œ ë‚ ì§œ, ì‹œê°„, ì¥ì†Œ, ì¤€ë¹„ë¬¼ì€ ë°˜ë“œì‹œ **êµµê²Œ** í‘œì‹œí•©ë‹ˆë‹¤
- ê° ì¹´í…Œê³ ë¦¬ ì•„ë˜ì— ë¶ˆë¦¿(-)ì„ ì‚¬ìš©í•˜ì—¬ í•­ëª©ì„ ë‚˜ì—´í•©ë‹ˆë‹¤
- ì˜¤ì§ ì •ë¦¬ëœ ì•Œë¦¼ì¥ ë³¸ë¬¸ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤ (ë©”íƒ€ ì •ë³´, ê¸€ììˆ˜, ë¶„ì„ ë‚´ìš©ì€ ì¶œë ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤)
</ì„œì‹ ê·œì¹™>`;

    const prompt = `êµì‚¬ê°€ ì‘ì„±í•œ ë©”ëª¨ë¥¼ ì•„ë˜ í˜•ì‹ì— ë§ì¶° ì•Œë¦¼ì¥ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

<ì¶œë ¥ í˜•ì‹>
# ${formattedDate} ì•Œë¦¼ì¥ ğŸ“‹

## ì¹´í…Œê³ ë¦¬ ì´ëª¨ì§€ ì¹´í…Œê³ ë¦¬ëª…
- ë¶ˆë¦¿ìœ¼ë¡œ í•­ëª© ë‚˜ì—´
- **ì¤‘ìš” ì •ë³´**ëŠ” êµµê²Œ í‘œì‹œ
</ì¶œë ¥ í˜•ì‹>

<ì¹´í…Œê³ ë¦¬ ëª©ë¡ (í•´ë‹¹ ë‚´ìš©ì´ ìˆëŠ” ì¹´í…Œê³ ë¦¬ë§Œ ì‚¬ìš©)>
ğŸ“š í•™ìŠµ ì•ˆë‚´ â€” ìˆ˜ì—…, ì‹œí—˜, ìˆ™ì œ, í•™ìŠµ ê´€ë ¨
ğŸ“¦ ì¤€ë¹„ë¬¼ â€” ê°€ì ¸ì˜¬ ê²ƒ, ì±™ê¸¸ ê²ƒ
ğŸ“… ì¼ì • ì•ˆë‚´ â€” í–‰ì‚¬, ì²´í—˜í•™ìŠµ, íŠ¹ë³„ ì¼ì •
ğŸ½ï¸ ê¸‰ì‹/ê°„ì‹ â€” ê¸‰ì‹, ê°„ì‹, ì‹ë‹¨ ê´€ë ¨
ğŸ‘• ë³µì¥/ìƒí™œ â€” ë³µì¥, ìƒí™œ ì§€ë„, ê·œì¹™
ğŸ’° ë‚©ë¶€/ì œì¶œ â€” ëˆ, ì„œë¥˜ ì œì¶œ ê´€ë ¨
ğŸ“¢ ê¸°íƒ€ ì•ˆë‚´ â€” ìœ„ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ì‚¬í•­
</ì¹´í…Œê³ ë¦¬ ëª©ë¡>

<ì¢‹ì€ ì˜ˆì‹œ>
# 2026ë…„ 3ì›” 5ì¼(ìˆ˜) ì•Œë¦¼ì¥ ğŸ“‹

## ğŸ“š í•™ìŠµ ì•ˆë‚´
- ë‚´ì¼ **ìˆ˜í•™ ë‹¨ì›í‰ê°€**ê°€ ìˆì–´ìš”. 3ë‹¨ì›ê¹Œì§€ ê¼­ ë³µìŠµí•´ ì£¼ì„¸ìš”!
- ë…ì„œë¡ì€ **ê¸ˆìš”ì¼ê¹Œì§€** ì œì¶œí•´ ì£¼ì„¸ìš”.

## ğŸ“¦ ì¤€ë¹„ë¬¼
- **ë¯¸ìˆ  ë„êµ¬** (í¬ë ˆíŒŒìŠ¤, ìŠ¤ì¼€ì¹˜ë¶)ë¥¼ ê¼­ ì±™ê²¨ ì£¼ì„¸ìš”.
- ì²´ìœ¡ë³µì€ **í™”ìš”ì¼, ëª©ìš”ì¼**ì— ì…ê³  ì™€ì£¼ì„¸ìš”.

## ğŸ“… ì¼ì • ì•ˆë‚´
- **3ì›” 10ì¼(ì›”)** ë´„ í˜„ì¥ì²´í—˜í•™ìŠµì´ ì˜ˆì •ë˜ì–´ ìˆì–´ìš”.
- ì¥ì†Œ: **ì„œìš¸ìˆ²**, ì¤€ë¹„ë¬¼: ë„ì‹œë½, ë—ìë¦¬
</ì¢‹ì€ ì˜ˆì‹œ>

<ì‘ì„± ì‹œ ì£¼ì˜>
- ì²« ì¤„ì€ ë°˜ë“œì‹œ "# ${formattedDate} ì•Œë¦¼ì¥ ğŸ“‹"ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤
- "í•™ë¶€ëª¨ë‹˜ê»˜", "ì•ˆë…•í•˜ì„¸ìš”" ê°™ì€ ì¸ì‚¬ë§ì€ ë„£ì§€ ì•ŠìŠµë‹ˆë‹¤
- ë‚´ìš©ì´ 1~2ê°œë¿ì´ë¼ë©´ ì¹´í…Œê³ ë¦¬ 1~2ê°œë§Œ ì‚¬ìš©í•´ë„ ë©ë‹ˆë‹¤
- ì›ë³¸ ë©”ëª¨ì— ì—†ëŠ” ë‚´ìš©ì„ ì„ì˜ë¡œ ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
</ì‘ì„± ì‹œ ì£¼ì˜>

**êµì‚¬ ë©”ëª¨ ì›ë¬¸:**
${text}`;

    try {
        const rawResult = await generateWithRetry({
            systemMessage,
            prompt,
            model: model || DEFAULT_MODEL,
        });

        // í›„ì²˜ë¦¬: ë©”íƒ€ ì •ë³´ ì œê±°
        const processed = cleanMetaInfo(rawResult);

        return processed;
    } catch (error) {
        console.error("Local LLM API Error:", error);
        throw error;
    }
}
